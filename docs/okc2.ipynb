{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('https://s3.amazonaws.com/techblog-static/interview_dataset.csv')\n",
    "# df.to_pickle('okc_df.pkl')\n",
    "df = pd.read_pickle('okc_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://brycexxx.github.io/2018/11/15/c4-assignment3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>label</th>\n",
       "      <th>Body_processed</th>\n",
       "      <th>Title_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26633</th>\n",
       "      <td>74726</td>\n",
       "      <td>&lt;p&gt;script async not working:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code...</td>\n",
       "      <td>&lt;script async&gt; not working in rails</td>\n",
       "      <td>0</td>\n",
       "      <td>script async not working : &lt; h1 &gt; welcome # in...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90392</th>\n",
       "      <td>65968</td>\n",
       "      <td>&lt;p&gt;In my JSF+Spring project i tried to add for...</td>\n",
       "      <td>&lt;rich:popupPanel buttons not working in JSF Pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>in my jsf + spring project i tried to add form...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               Body  \\\n",
       "26633       74726  <p>script async not working:</p>\\n\\n<pre><code...   \n",
       "90392       65968  <p>In my JSF+Spring project i tried to add for...   \n",
       "\n",
       "                                                   Title  label  \\\n",
       "26633                <script async> not working in rails      0   \n",
       "90392  <rich:popupPanel buttons not working in JSF Pr...      0   \n",
       "\n",
       "                                          Body_processed Title_processed  \n",
       "26633  script async not working : < h1 > welcome # in...             NaN  \n",
       "90392  in my jsf + spring project i tried to add form...             NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the only row is missing is where the preprocessor failed. Since these are only two rows, we drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>label</th>\n",
       "      <th>Body_processed</th>\n",
       "      <th>Title_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33226</td>\n",
       "      <td>&lt;p&gt;Hi I'm new to &lt;code&gt;Ruby on Rails&lt;/code&gt;. I...</td>\n",
       "      <td>RUBY: most common number for Users</td>\n",
       "      <td>1</td>\n",
       "      <td>hi i'm new to ruby on rails . i created users ...</td>\n",
       "      <td>ruby : most common number for users</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39763</td>\n",
       "      <td>&lt;p&gt;I have a search engine on PHP that have ind...</td>\n",
       "      <td>Scan a webpage and get the video embed url only</td>\n",
       "      <td>1</td>\n",
       "      <td>i have a search engine on php that have indexe...</td>\n",
       "      <td>scan a webpage and get the video embed url only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9698</td>\n",
       "      <td>&lt;p&gt;For my website I want to have divs out of t...</td>\n",
       "      <td>Use jQuery or Javascript to move elements into...</td>\n",
       "      <td>1</td>\n",
       "      <td>for my website i want to have divs out of the ...</td>\n",
       "      <td>use jquery or javascript to move elements into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5948</td>\n",
       "      <td>&lt;p&gt;I'm looking for a dead simple Java Library ...</td>\n",
       "      <td>Java SFTP Transfer Library</td>\n",
       "      <td>1</td>\n",
       "      <td>i'm looking for a dead simple java library to ...</td>\n",
       "      <td>java sftp transfer library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27955</td>\n",
       "      <td>&lt;p&gt;Having two MySql databases with same struct...</td>\n",
       "      <td>How to Merge two Mysql Databases with same str...</td>\n",
       "      <td>1</td>\n",
       "      <td>having two mysql databases with same structure...</td>\n",
       "      <td>how to merge two mysql databases with same str...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Body  \\\n",
       "0       33226  <p>Hi I'm new to <code>Ruby on Rails</code>. I...   \n",
       "2       39763  <p>I have a search engine on PHP that have ind...   \n",
       "4        9698  <p>For my website I want to have divs out of t...   \n",
       "5        5948  <p>I'm looking for a dead simple Java Library ...   \n",
       "6       27955  <p>Having two MySql databases with same struct...   \n",
       "\n",
       "                                               Title  label  \\\n",
       "0                 RUBY: most common number for Users      1   \n",
       "2    Scan a webpage and get the video embed url only      1   \n",
       "4  Use jQuery or Javascript to move elements into...      1   \n",
       "5                         Java SFTP Transfer Library      1   \n",
       "6  How to Merge two Mysql Databases with same str...      1   \n",
       "\n",
       "                                      Body_processed  \\\n",
       "0  hi i'm new to ruby on rails . i created users ...   \n",
       "2  i have a search engine on php that have indexe...   \n",
       "4  for my website i want to have divs out of the ...   \n",
       "5  i'm looking for a dead simple java library to ...   \n",
       "6  having two mysql databases with same structure...   \n",
       "\n",
       "                                     Title_processed  \n",
       "0                ruby : most common number for users  \n",
       "2    scan a webpage and get the video embed url only  \n",
       "4  use jquery or javascript to move elements into...  \n",
       "5                         java sftp transfer library  \n",
       "6  how to merge two mysql databases with same str...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label==1].iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>label</th>\n",
       "      <th>Body_processed</th>\n",
       "      <th>Title_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64804</td>\n",
       "      <td>&lt;p&gt;I know that StringBuffer class is synchroni...</td>\n",
       "      <td>What exactly does it mean when they say that S...</td>\n",
       "      <td>0</td>\n",
       "      <td>i know that stringbuffer class is synchronized...</td>\n",
       "      <td>what exactly does it mean when they say that s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51270</td>\n",
       "      <td>&lt;p&gt;Is there any way to get ICY metadata from s...</td>\n",
       "      <td>ICY metadata support with ffmpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>is there any way to get icy metadata from shou...</td>\n",
       "      <td>icy metadata support with ffmpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55001</td>\n",
       "      <td>&lt;p&gt;Hi I have 3 soap requests. \\nSay.\\nReq1 \\nR...</td>\n",
       "      <td>How can I pipeline multiple soap requests usin...</td>\n",
       "      <td>0</td>\n",
       "      <td>hi i have 3 soap requests . say . req1 req2 re...</td>\n",
       "      <td>how can i pipeline multiple soap requests usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50875</td>\n",
       "      <td>&lt;p&gt;Consider the following entity-relationship ...</td>\n",
       "      <td>Mapping many-to-many relationship with attribu...</td>\n",
       "      <td>0</td>\n",
       "      <td>consider the following entity - relationship d...</td>\n",
       "      <td>mapping many - to - many relationship with att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>64298</td>\n",
       "      <td>&lt;p&gt;I am trying to strip all \"?\" in file names ...</td>\n",
       "      <td>Recursively rename directories and files based...</td>\n",
       "      <td>0</td>\n",
       "      <td>i am trying to strip all \"?\" in file names in ...</td>\n",
       "      <td>recursively rename directories and files based...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                               Body  \\\n",
       "1        64804  <p>I know that StringBuffer class is synchroni...   \n",
       "3        51270  <p>Is there any way to get ICY metadata from s...   \n",
       "7        55001  <p>Hi I have 3 soap requests. \\nSay.\\nReq1 \\nR...   \n",
       "8        50875  <p>Consider the following entity-relationship ...   \n",
       "14       64298  <p>I am trying to strip all \"?\" in file names ...   \n",
       "\n",
       "                                                Title  label  \\\n",
       "1   What exactly does it mean when they say that S...      0   \n",
       "3                    ICY metadata support with ffmpeg      0   \n",
       "7   How can I pipeline multiple soap requests usin...      0   \n",
       "8   Mapping many-to-many relationship with attribu...      0   \n",
       "14  Recursively rename directories and files based...      0   \n",
       "\n",
       "                                       Body_processed  \\\n",
       "1   i know that stringbuffer class is synchronized...   \n",
       "3   is there any way to get icy metadata from shou...   \n",
       "7   hi i have 3 soap requests . say . req1 req2 re...   \n",
       "8   consider the following entity - relationship d...   \n",
       "14  i am trying to strip all \"?\" in file names in ...   \n",
       "\n",
       "                                      Title_processed  \n",
       "1   what exactly does it mean when they say that s...  \n",
       "3                    icy metadata support with ffmpeg  \n",
       "7   how can i pipeline multiple soap requests usin...  \n",
       "8   mapping many - to - many relationship with att...  \n",
       "14  recursively rename directories and files based...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label==0].iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Body_length'] = df.Body_processed.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210.8884877697554"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Body_length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284.05628225129004\n",
      "137.72362\n"
     ]
    }
   ],
   "source": [
    "print(df[df['label'] == 0]['Body_length'].mean())\n",
    "print(df[df['label'] == 1]['Body_length'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title_length'] = df.Title_processed.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.41084821696434"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Title_length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.722528901156046\n",
      "9.09918\n"
     ]
    }
   ],
   "source": [
    "print(df[df['label'] == 0]['Title_length'].mean())\n",
    "print(df[df['label'] == 1]['Title_length'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161065\n"
     ]
    }
   ],
   "source": [
    "results = set()\n",
    "df[df['label'] == 1]['Body_processed'].str.lower().str.split().apply(results.update)\n",
    "print(len(list(results)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354779\n"
     ]
    }
   ],
   "source": [
    "results = set()\n",
    "df[df['label'] == 0]['Body_processed'].str.lower().str.split().apply(results.update)\n",
    "print(len(list(results)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possibly : add the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Title_processed'] + df['Body_processed'], \n",
    "                                                    df['label'], \n",
    "                                                    random_state=0)\n",
    "def answer_two():\n",
    "    vect = CountVectorizer().fit(X_train)\n",
    "    tokens = vect.get_feature_names()\n",
    "    return sorted(tokens, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = answer_two()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marié',\n",
       " 'mark1',\n",
       " 'mark2',\n",
       " 'mark3',\n",
       " 'marki',\n",
       " 'marko',\n",
       " 'marks',\n",
       " 'marry',\n",
       " 'marsh',\n",
       " 'marst']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[50000:50010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "def answer_four():\n",
    "    vect = TfidfVectorizer().fit(X_train)\n",
    "    feature_names = np.array(vect.get_feature_names()).reshape(-1, 1)\n",
    "    X_train_vectorized = vect.transform(X_train)\n",
    "    tfidf_values = X_train_vectorized.max(0).toarray()[0].reshape(-1, 1)\n",
    "    tfidf_df = pd.DataFrame(data=np.hstack((feature_names, tfidf_values)), columns=['features', 'tfidf'])\n",
    "    smallest_tfidf = tfidf_df.sort_values(by=['tfidf', 'features']).set_index('features')[:20]\n",
    "    largest_tfidf = tfidf_df.sort_values(by=['tfidf', 'features'], ascending=[False, True]).set_index('features')[:20]\n",
    "    return smallest_tfidf['tfidf'].apply(float), largest_tfidf['tfidf'].apply(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(features\n",
       " 0303                                           0.001006\n",
       " 06011982                                       0.001006\n",
       " 0863                                           0.001006\n",
       " 805917662                                      0.001006\n",
       " agl                                            0.001006\n",
       " bankruptcies                                   0.001006\n",
       " businessdecisionresultoverride                 0.001006\n",
       " createnewoutputrows                            0.001006\n",
       " dcqjwzg                                        0.001006\n",
       " engy                                           0.001006\n",
       " getcacheentryrspxml                            0.001006\n",
       " individualalerts                               0.001006\n",
       " individualcommercialdecision                   0.001006\n",
       " judgements                                     0.001006\n",
       " mktg                                           0.001006\n",
       " proprietorships                                0.001006\n",
       " summons                                        0.001006\n",
       " vedascorefinancialcommercialplusconsumer1_1    0.001006\n",
       " writs                                          0.001006\n",
       " 28t06                                          0.001490\n",
       " Name: tfidf, dtype: float64,\n",
       " features\n",
       " 00              0.999471\n",
       " 45280550        0.999147\n",
       " chr             0.997411\n",
       " quot            0.995811\n",
       " lorem           0.988419\n",
       " 41              0.987406\n",
       " nbsp            0.985366\n",
       " 0x00            0.982427\n",
       " level4          0.980428\n",
       " bla             0.979027\n",
       " level5          0.976256\n",
       " arr             0.976015\n",
       " li              0.975752\n",
       " na_real_        0.975455\n",
       " randomnumber    0.971248\n",
       " deletedmust     0.970520\n",
       " gameboard       0.970466\n",
       " mult            0.969553\n",
       " bowlingarray    0.969433\n",
       " td              0.968750\n",
       " Name: tfidf, dtype: float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_four()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def answer_five():\n",
    "    vect = TfidfVectorizer(min_df=3).fit(X_train)\n",
    "    X_train_vectorized = vect.transform(X_train)\n",
    "    X_test_vectorized = vect.transform(X_test)\n",
    "    clf = MultinomialNB(alpha=0.1).fit(X_train_vectorized, y_train)\n",
    "    y_score = clf.predict_proba(X_test_vectorized)[:, 1]\n",
    "    score = roc_auc_score(y_test, y_score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84107187564574"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_five()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature(X, feature_to_add):\n",
    "    \"\"\"\n",
    "    Returns sparse feature matrix with added feature.\n",
    "    feature_to_add can also be a list of features.\n",
    "    \"\"\"\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def answer_seven2():\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    temp = df.copy()\n",
    "    temp['length_of_doc'] = df['Body_processed'].str.len()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(temp.drop('label', axis=1),\n",
    "                                                        temp['label'] , random_state=0)\n",
    "    vect = TfidfVectorizer(min_df=5).fit(X_train['Body_processed'])\n",
    "    \n",
    "    X_train_vectorized_body = vect.transform(X_train['Body_processed'])\n",
    "    X_train_vectorized_title = vect.transform(X_train['Title_processed'])\n",
    "    X_train_vectorized = hstack([X_train_vectorized_body, X_train_vectorized_title],\n",
    "                                'csr')\n",
    "    \n",
    "    clf = MultinomialNB(alpha=0.1).fit(X_train_vectorized, y_train)\n",
    "    \n",
    "    X_test_vectorized_body = vect.transform(X_test['Body_processed'])  \n",
    "    X_test_vectorized_title = vect.transform(X_test['Title_processed'])\n",
    "    X_test_vectorized = hstack([X_test_vectorized_body, X_test_vectorized_title],\n",
    "                                'csr')\n",
    "    \n",
    "    y_score = clf.predict_proba(X_test_vectorized)[:, 1]\n",
    "    score = roc_auc_score(y_test, y_score)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8482461288589771"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_seven2() # increased slightly by keeping title & body separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def answer_seven():\n",
    "    temp = df.copy()\n",
    "    temp['length_of_doc'] = df['Body_processed'].str.len()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(temp.drop('label', axis=1),\n",
    "                                                        temp['label'] , random_state=0)\n",
    "    vect = TfidfVectorizer(min_df=5).fit(X_train['Body_processed'])\n",
    "    X_train_vectorized = vect.transform(X_train['Body_processed'])\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, X_train['length_of_doc'])\n",
    "    clf = SVC(C=10000).fit(X_train_vectorized, y_train)\n",
    "    X_test_vectorized = vect.transform(X_test['text'])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, X_test['length_of_doc'])\n",
    "    y_score = clf.decision_function(X_test_vectorized)\n",
    "    score = roc_auc_score(y_test, y_score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer_seven()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('colext', TextSelector(field='Body_processed')),\n",
       "                ('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.25, max_features=None,\n",
       "                                 min_df=0.0025, ngram_range=(1, 3), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function Tokenizer at 0x1267e5700>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('svd',\n",
       "                 TruncatedSVD(algorithm='randomized', n_components=300,\n",
       "                              n_iter=5, random_state=None, tol=0.0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "import re\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def Tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    porter_stemmer=nltk.PorterStemmer()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "\n",
    "Pipeline([('colext', TextSelector('Body_processed')),\n",
    "          ('tfidf', TfidfVectorizer(tokenizer=Tokenizer,\n",
    "                     min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "          ('svd', TruncatedSVD(algorithm='randomized', n_components=300)), #for XGB\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.field]\n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[[self.field]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('colext', TextSelector('Text')),\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, #stop_words=stop_words,\n",
    "                     min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=100)), #for XGB\n",
    "        ])),\n",
    "        ('words', Pipeline([\n",
    "            ('wordext', NumberSelector('Body_length')),\n",
    "            ('wscaler', StandardScaler()),\n",
    "        ])),\n",
    "    ])),\n",
    "    ('clf', XGBClassifier(max_depth=3, n_estimators=100, learning_rate=0.1)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Body', 'Title', 'label', 'Body_processed',\n",
       "       'Title_processed', 'Body_length', 'Title_length', 'comb', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Body_processed'] + df['Title_processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Body', 'Title', 'label', 'Body_processed',\n",
       "       'Title_processed', 'Body_length', 'Title_length', 'comb', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Text', 'Body_length']]\n",
    "y = df['label']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)\n",
    "preds = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@kocur4d/hyper-parameter-tuning-with-pipelines-5310aff069d6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:so_text] *",
   "language": "python",
   "name": "conda-env-so_text-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
